DataSource=Exp

Epochs=100
BatchSize=0
Loss=MeanSquaredError
KeepBest=1
ReboostEveryEpochs=-1
ClassBalancingWeightLoss=0
Optimizer=Adam
LearningRate=-1
Decay=-1
Momentum=-1

Engine=BeeDNN
NbLayers=3
Problem=Regression

Layer1.type=Dense
Layer1.hasBias=1
Layer1.inputSize=1
Layer1.outputSize=5
Layer1.weight=
3.754 3.333 -1.016 -0.514 0.008106 
Layer1.bias=
-4.923 -9.985 3.074 1.807 -0.1489 

Layer2.type=Relu

Layer3.type=Dense
Layer3.hasBias=1
Layer3.inputSize=5
Layer3.outputSize=1
Layer3.weight=
2.305 
7.989 
-1.951 
2.912 
-0.04054 
Layer3.bias=
2.081 

Notes=
 Toy fitting sample:  - first level is 1 -> 5 dense - 5 activation function  - last level is 5 ->1 dense .  Goals is to play with optimizers/activations
